{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec836a5-54b1-4cdf-b454-2be5e4c21ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:silx.opencl.common:Unable to import pyOpenCl. Please install it from: https://pypi.org/project/pyopencl\n"
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "import pyxem as px\n",
    "from diffsims import generators\n",
    "import tensorflow as tf\n",
    "import diffpy.structure\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import hyperspy as hs\n",
    "from tqdm import tqdm\n",
    "from diffpy.structure import loadStructure\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae12404c-5e73-468c-a90f-7ca66533be1b",
   "metadata": {},
   "source": [
    "## Experimental data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ddf50-d5b1-4e8d-a29d-1d1194f204a7",
   "metadata": {},
   "source": [
    "### Load and rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d089569-b8de-46db-8236-d57bb10ab24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'E:\\Elisabeth\\Al-Cu-Li-Emil\\Data'.replace('\\\\', '\\\\\\\\'))\n",
    "signal = hs.io.load(r'SPED_600x600x12_10x10_4p63x4p63_1deg_100Hz_CL12cm_NBD_alpha5_spot1p3_preprocessed.hspy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83bf9c41-598d-4f1b-876b-2f36eebae6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 53.30 s\n"
     ]
    }
   ],
   "source": [
    "# The experimental data is rotated to avoid rotating the simulations for the training database. The rotation angle rot_angle can be found with the approach described in the \n",
    "# vector analysis approach or by trial-and-error. \n",
    "\n",
    "rot_angle = -60.35\n",
    "signal = signal.rotate_diffraction(rot_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c89c8c4-9f94-4586-8b09-400c628edb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cea816-d310-4e51-8d29-232f28cf8e0c",
   "metadata": {},
   "source": [
    "### Preprocess experimental data: Apply log transformation (Eq. 3) and mask out central beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f14b288-7930-43c3-bfda-3af049eb9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import log10\n",
    "\n",
    "def log_shift(raw,base=10,shift=0.1):\n",
    "    ''''\n",
    "    Parameters\n",
    "    -------\n",
    "    raw : np.array((nx, ny)). The raw data.\n",
    "    shift : float. Introduces a shift for the log. To account for pixels with 0 value.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    log_shift : np.array((nx, ny)). The log transformation of the raw data.\n",
    "    '''\n",
    "    log_shift = log10(raw+shift) - log10(shift)\n",
    "    return log_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c653da6-b90a-4f13-b632-492e5f010bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(stack, only_one_image=False):\n",
    "    ''''\n",
    "    Normalizes one or multiple DPs between [0,1].\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    stack : np.array((nx,ny)) or list of np.array((nx,ny)). Single or multiple DPs to be normalized.\n",
    "    only_one_image : boolean. If set to True, stack is one image. If set to False, stack is a list of numpy arrays.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    normalized_stack : numpy array with same shape as stack. \n",
    "    '''\n",
    "    normalized_stack = np.zeros_like(stack, dtype='float32')\n",
    "    if only_one_image:\n",
    "        normalized_stack = stack/(float(np.max(stack) - np.min(stack)))\n",
    "        return normalized_stack\n",
    "    \n",
    "    n_images = stack.shape[0]\n",
    "    print('Normalizing between 0 and 1..')\n",
    "    for i in tqdm(range(n_images)):\n",
    "        normalized_stack[i] = stack[i]/(float(np.max(stack[i]) - np.min(stack[i])))\n",
    "    return normalized_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c79b13-3836-4a15-b7e3-b29c8ed07f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_NN(signal, mask_size, shift):\n",
    "    ''''\n",
    "    Preprocesses the experimental prior to NN prediction: A log shift is imposed before a mask is applied to mask out the central beam. The 4D dataset is reshaped to (nx*ny, kx, ky)\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    signal : pyxem.signals.electron_diffraction2d.ElectronDiffraction2D((nx,ny,kx,ky)\n",
    "    mask_size : int - The size of the central beam mask\n",
    "    shift : float - The shift in Eq. 3.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    signal_preprocessed : numpy.ndarray((nx*ny, kx, ky))\n",
    "    '''\n",
    "    central_beam_mask = px.utils.expt_utils.circular_mask((128,128), mask_size)\n",
    "    DP_scale = signal.axes_manager[2].scale\n",
    "    signal_masked_px = signal*~central_beam_mask\n",
    "    nx, ny = signal_masked_px.data.shape[0], signal_masked_px.data.shape[1]\n",
    "    kx, ky = signal_masked_px.data.shape[2], signal_masked_px.data.shape[3]\n",
    "    signal_masked = signal_masked_px.data.reshape(nx*ny, kx, ky)\n",
    "    print('Scaling the intensity..')\n",
    "    for i in tqdm(range(len(signal_masked))):\n",
    "         signal_masked[i] = log_shift(signal_masked[i], shift=shift)\n",
    "    return normalize(signal_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c078bf53-88e9-4603-9269-3509e57ada8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling the intensity..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 262144/262144 [00:26<00:00, 9772.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing between 0 and 1..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 262144/262144 [00:08<00:00, 30760.55it/s]\n"
     ]
    }
   ],
   "source": [
    "mask_size = 11\n",
    "shift = 0.024\n",
    "nx, ny, kx, ky = 512, 512, 128, 128\n",
    "signal_masked = preprocess_NN(signal, mask_size, shift)\n",
    "signal_masked_px = px.signals.ElectronDiffraction2D(signal_masked.reshape(nx, ny, kx, ky))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be94ac16-5a5a-43ba-bf16-fa6c08a9202c",
   "metadata": {},
   "source": [
    "## Training data creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a80bf-ff1e-4f8d-841e-09eac565fe24",
   "metadata": {},
   "source": [
    "### Load and create structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b06af478-1b81-47df-aee4-075b2da49e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lattice vectors: theta prime: Lattice(a=4.04, b=4.04, c=5.8, alpha=90, beta=90, gamma=90), T1: Lattice(a=4.94775, b=4.94775, c=14.145, alpha=90, beta=90, gamma=120). Al: Lattice(a=4.04, b=4.04, c=4.04, alpha=90, beta=90, gamma=90)\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'H:\\PhD\\CNN\\Models\\Precipitates'.replace('\\\\', '\\\\\\\\'))\n",
    "\n",
    "thetaprime = loadStructure('thetaprime.cif', fmt=\"cif\")\n",
    "T1 = loadStructure('T1-a_Al-4p04.cif', fmt=\"cif\")\n",
    "Al = loadStructure('Al_mp-134_conventional_standard.cif', fmt=\"cif\")\n",
    "print('Lattice vectors: theta prime: {}, T1: {}. Al: {}'.format(thetaprime.lattice, T1.lattice, Al.lattice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49c3a8dd-1317-4da3-b620-f97a68d0ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Al(a,b):\n",
    "    ''''\n",
    "    Creates a diffpy.structure of Al. Has the option of varying the lattice parameter in-plane to account for strain.\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    a : The a lattice parameter of Al.\n",
    "    b : The b lattice parameter of Al.\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    structure_Al : diffpy.structure of Al\n",
    "    '''\n",
    "    Al_latt = diffpy.structure.Lattice(a=a,b=b,c=4.04, alpha=90,beta=90,gamma=90 )\n",
    "    Al_atom=diffpy.structure.atom.Atom(atype='Al',xyz=[0,0,0], lattice=Al_latt)\n",
    "    Al_atom1=diffpy.structure.atom.Atom(atype='Al',xyz=[0,0.5,0.5], lattice=Al_latt)\n",
    "    Al_atom2=diffpy.structure.atom.Atom(atype='Al',xyz=[0.5,0,0.5], lattice=Al_latt)\n",
    "    Al_atom3=diffpy.structure.atom.Atom(atype='Al',xyz=[0.5,0.5,0], lattice=Al_latt)\n",
    "    structure_Al = diffpy.structure.Structure(atoms=[Al_atom, Al_atom1, Al_atom2, Al_atom3], lattice=Al_latt)\n",
    "    return structure_Al"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf942f7-d300-4a49-8dba-56f55d6e1ed7",
   "metadata": {},
   "source": [
    "### Create training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cb6fe1b-549d-4bc5-8d8d-565204f7fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate reciprocal space\n",
    "\n",
    "DP_scale = signal.axes_manager[2].scale\n",
    "target_pattern_dimensions_pixels = signal.axes_manager[2].size\n",
    "half_size = target_pattern_dimensions_pixels//2\n",
    "diffraction_calibration = DP_scale\n",
    "reciprocal_radius = diffraction_calibration*(half_size-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b5f662-5ee9-4753-89ad-1ff7239dad9f",
   "metadata": {},
   "source": [
    "#### Add noise functions to ensure generality of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fa38314-406e-4f3d-9bf3-3fa554f65e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(raw_data):\n",
    "    ''''\n",
    "    Parameters\n",
    "    --------\n",
    "    raw_data : np.array((kx,ky)). Holding the raw DP.\n",
    "    \n",
    "    Returns:\n",
    "    gaussian_noise + raw_data : np.array((kx,ky)). The resulting noisy DP.\n",
    "    '''\n",
    "    #gaussian_noise = np.random.rand(128, 128)/(30 + 40*(np.random.rand() - 0.5))\n",
    "    gaussian_noise = np.random.rand(128, 128)/(400 + 370*(np.random.rand() - 0.5)) #400 350\n",
    "    return gaussian_noise + raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe746415-f960-48a7-885f-26fd595c6911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radial_noise(raw_data, plot=False):\n",
    "    ''''\n",
    "    Takes the raw data and superimposes radial noise onto the pattern.\n",
    "    \n",
    "    Parameters\n",
    "    -------\n",
    "    raw_data : np.array((kx,ky)). Holding the raw DP.\n",
    "    plot : if True, the resulting DP will be plotted.\n",
    "    \n",
    "    Returns:\n",
    "    arr + raw_data : np.array((kx,ky)). The resulting noisy DP.\n",
    "    '''\n",
    "    x_axis = np.linspace(-1, 1, raw_data.shape[0])[:, None]\n",
    "    y_axis = np.linspace(-1, 1, raw_data.shape[1])[None, :]\n",
    "    arr = np.sqrt(x_axis**2 + y_axis**2)\n",
    "    \n",
    "    inner = 0.5 + (np.random.rand() - 0.5)*0.3 # 0.2 + (np.random.rand() - 0.5)*0.4\n",
    "    outer = 0\n",
    "    arr /= arr.max()\n",
    "    \n",
    "    exp = (6 + (2 * (np.random.rand() - 0.5))) # 5\n",
    "    arr = ((1 - arr) * inner)**exp\n",
    "\n",
    "    if plot:\n",
    "        fig,ax=plt.subplots(1,2,sharex=True,sharey=True)\n",
    "        ax[0].imshow(arr)\n",
    "        ax[1].imshow(arr+raw_data)\n",
    "    return arr + raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec789863-8102-4c03-aa90-d97722f556d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_noise(raw_data):\n",
    "    ''''\n",
    "    Parameters\n",
    "    --------\n",
    "    raw_data: np.array((kx,ky))\n",
    "    Returns:\n",
    "    poisson_noise + raw_data : np.array((kx,ky)). The resulting noisy DP.\n",
    "    '''\n",
    "    poisson_noise = np.random.poisson(raw_data)/(9 + 5*(np.random.rand() - 0.5))\n",
    "    return poisson_noise + raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b84556b-d8e1-4a0a-ad48-f06e3b1f86d0",
   "metadata": {},
   "source": [
    "#### Simulate the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "865a53c6-eaa4-4ee7-8ed6-81e09ac5e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_Al():\n",
    "    a=np.random.normal(loc=4.04, scale = 0.007)\n",
    "    b=np.random.normal(loc=4.04, scale = 0.007)\n",
    "    i = np.random.randint(2)\n",
    "    if i%2==0:\n",
    "        struc_Al = create_Al(a, a)\n",
    "    else:\n",
    "        struc_Al = create_Al(a,b)\n",
    "    return struc_Al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8879bc6c-d9f1-405e-8879-1657a99fa8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(structure, label, diffraction_calibration, weight, num_iterations, euler_angles, HT, relrods, relrods_Al):\n",
    "    ''''\n",
    "    Parameters\n",
    "    --------\n",
    "    structure : The structure to be simulated. If 'Al', the Al structure will be created inside the function to vary the lattice parameters to account for strain\n",
    "    label : int - The label of the structure\n",
    "    diffraction_calibration : float\n",
    "    weigt : float\n",
    "    num_iterations : int - The number of simulations per structure\n",
    "    euler_angles : List holding all three euler angles\n",
    "    HT : int - The high tension voltage used in the TEM experiments\n",
    "    relrods : A list holding the lower and upper value for the excitation error for each precipitate\n",
    "    relrods_Al : A list holding the lower and upper value for the excitation error for Al\n",
    "    \n",
    "    Returns:\n",
    "    patterns : A list with length num_iterations holding the simulated patterns of structure\n",
    "    labels : A list with length num_iterations holding the labels of structure\n",
    "    '''\n",
    "    central_beam_mask = px.utils.expt_utils.circular_mask((128,128), 11)\n",
    "    ediff = generators.diffraction_generator.DiffractionGenerator(HT, shape_factor_model='lorentzian')\n",
    "    \n",
    "    #Ensure that we have the same amount of simulated patterns per zone axis of precipitates:\n",
    "    if structure == structure_thetaprime_100:\n",
    "        num_iterations = int(num_iterations/2)\n",
    "\n",
    "    elif structure == structure_T1:\n",
    "        num_iterations = int(num_iterations/2)\n",
    "    \n",
    "    labels = np.zeros((num_iterations), dtype='int')\n",
    "    patterns = np.zeros((num_iterations, 128, 128), dtype='float32')\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Simulation parameters:\n",
    "        phi_A = 3 * (np.random.rand() - 0.5) # Slightly change the in-plane rotation\n",
    "        phi_T = 4*(np.random.rand() - 0.5) # Slightly change the sample tilt\n",
    "        rand_eulerx =4*(np.random.rand() - 0.5)\n",
    "        \n",
    "        weight_effective = (weight[1] - weight[0]) * np.random.random_sample() + weight[0] # Varies the weighting between Al and precipitate\n",
    "        sim = 1.9 + (np.random.rand()-0.5)*0.6 # Varies the size of the diffracted reflections\n",
    "        relrod = (relrods[0] - relrods[1]) * np.random.random_sample() + relrods[1] # Varies the excitation error for the precipitates\n",
    "        relrod_Al = (relrods_Al[0] - relrods_Al[1]) * np.random.random_sample() + relrods_Al[1] # Varies the excitation error for Al\n",
    "        \n",
    "        # Account for all the orientation relationships of the precipitates:\n",
    "        if structure != 'Al':\n",
    "            diffraction_Al = ediff.calculate_ed_data(structure_Al(), reciprocal_radius=reciprocal_radius, max_excitation_error=relrod_Al, with_direct_beam=False,\n",
    "                                             rotation=(phi_A, rand_eulerx, phi_T))\n",
    "            diffraction_Al.calibration = diffraction_calibration\n",
    "            pattern_Al = diffraction_Al.get_diffraction_pattern((128, 128), sigma=sim)\n",
    "            diffraction_preci = ediff.calculate_ed_data(structure, reciprocal_radius=reciprocal_radius, max_excitation_error=relrod, with_direct_beam=False,\n",
    "                                                  rotation=(phi_A + euler_angles[0], rand_eulerx + euler_angles[1], phi_T + euler_angles[2]))\n",
    "            diffraction_preci.calibration = diffraction_calibration\n",
    "            pattern_preci = diffraction_preci.get_diffraction_pattern((128, 128), sigma=sim)\n",
    "            pattern_preci = np.average(np.array([pattern_preci, weight_effective*pattern_Al]),axis=0)\n",
    "        else:\n",
    "            diffraction_Al = ediff.calculate_ed_data(structure_Al(), reciprocal_radius=reciprocal_radius, max_excitation_error=relrod_Al, with_direct_beam=False,\n",
    "                                             rotation=(phi_A, rand_eulerx, phi_T)) \n",
    "            diffraction_Al.calibration = diffraction_calibration\n",
    "            pattern_Al = diffraction_Al.get_diffraction_pattern((128,128), sigma=sim)\n",
    "            pattern_preci = pattern_Al\n",
    "        pattern_preci = normalize(pattern_preci, only_one_image=True)\n",
    "        pattern_preci = poisson_noise(pattern_preci)\n",
    "        pattern_preci = gaussian_noise(pattern_preci)\n",
    "        pattern_preci = radial_noise(pattern_preci, plot=False)\n",
    "        pattern_preci = log_shift(pattern_preci, shift=((0.10 - 0.01) * np.random.random_sample() + 0.01)) #0.15 - 0.01\n",
    "        pattern_preci = normalize(pattern_preci, only_one_image=True)\n",
    "        pattern_preci = pattern_preci * ~central_beam_mask\n",
    "        pattern_preci = pattern_preci.astype('float32')\n",
    "        patterns[i] = pattern_preci\n",
    "        labels[i] = label\n",
    "    return patterns, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32a0656e-e52e-4e88-9ac6-26be5311c750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulations..\n",
      "Simulation bulk nr  0\n",
      "Simulation bulk nr  1\n",
      "Simulation bulk nr  2\n",
      "Simulation bulk nr  3\n",
      "Simulation bulk nr  4\n",
      "Simulation bulk nr  5\n"
     ]
    }
   ],
   "source": [
    "structure_thetaprime_100 = thetaprime.copy()\n",
    "structure_thetaprime_001 = thetaprime.copy()\n",
    "structure_T1 = T1.copy()\n",
    "\n",
    "print('Starting simulations..')\n",
    "\n",
    "structures = ['Al', structure_thetaprime_100, structure_thetaprime_100, structure_thetaprime_001, structure_T1, structure_T1]\n",
    "structure_labels = np.array([0, 1, 1, 2, 3, 3], dtype='int')\n",
    "num_iter = 10000\n",
    "\n",
    "euler_angles = [[0, 0, 0], [0, 90, 0], [90, 90, 0], [0, 0, 0], [45, 54.7, 60], [-45, 54.7, 60]]\n",
    "weight = [[1,1], [1 ,10], [1, 10],  [1., 50], [1., 550], [1., 550]] #600 T1 #faceon 28 # edgeon 1 10\n",
    "relrods = [[0.11, 0.04], [0.3, 0.02], [0.3, 0.02], [0.15, 0.02], [0.15, 0.01],  [0.15, 0.01]]\n",
    "relrod_Al = [0.15, 0.02]\n",
    "\n",
    "target_pattern_dimensions_pixels = 128\n",
    "half_size = target_pattern_dimensions_pixels//2\n",
    "diffraction_calibration = signal.axes_manager[2].scale\n",
    "reciprocal_radius = diffraction_calibration*(half_size-1)\n",
    "\n",
    "for i in range(len(structures)):\n",
    "    print('Simulation bulk nr ', i)\n",
    "    patterns, labels = simulate(structure=structures[i], label=structure_labels[i], diffraction_calibration=diffraction_calibration, weight = weight[i], \n",
    "                                num_iterations=num_iter, euler_angles=euler_angles[i], HT=200, \n",
    "                                relrods = relrods[i], relrods_Al=relrod_Al)\n",
    "    if i == 0:\n",
    "        all_patterns, all_labels = patterns.copy(), labels.copy()\n",
    "    else:\n",
    "        all_patterns = np.concatenate((all_patterns, patterns))\n",
    "        all_labels = np.concatenate((all_labels, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "aae11fa2-85af-43d2-bfab-79b2481e13d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(arr=all_patterns, file=directory + '/training_data.npy')\n",
    "np.save(arr=all_labels, file=directory + '/labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "10c2f090-8bea-4077-9376-5f1e844714bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 20\n",
    "start = 2*10000\n",
    "fig,ax = plt.subplots(4,4)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax[i,j].imshow(all_patterns[start + a], vmax=.5)\n",
    "        ax[i,j].set_title(all_labels[start+ a])\n",
    "        a+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8b0821-5230-435d-9af7-cee74628d10e",
   "metadata": {},
   "source": [
    "### Split into training, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4da69f80-1b20-41b2-8f9d-bbb4d1a24c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of patterns: 40000. Patterns in train set: 32000. Patterns in validation set: 4000. Patterns in test set: 4000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "num_patterns = len(all_patterns)\n",
    "all_labels_shuffled = []\n",
    "all_patterns_shuffled = []\n",
    "\n",
    "all_labels_shuffled, all_patterns_shuffled = shuffle(all_labels, all_patterns)\n",
    "\n",
    "train_size = 0.8\n",
    "\n",
    "train_data, rem_data, train_label, rem_label = train_test_split(all_patterns_shuffled, all_labels_shuffled,\n",
    "                                                               train_size=train_size)\n",
    "\n",
    "test_size = 0.5\n",
    "test_data, val_data, test_label, val_label = train_test_split(rem_data, rem_label, train_size=test_size)\n",
    "\n",
    "test_data, val_data, train_data, test_label, val_label, train_label = np.asarray(test_data), np.asarray(val_data), np.asarray(train_data), np.asarray(test_label), np.asarray(val_label), np.asarray(train_label)\n",
    "\n",
    "\n",
    "print('Total number of patterns: {}. Patterns in train set: {}. Patterns in validation set: {}. Patterns in test set: {}'.format(all_patterns.shape[0],train_data.shape[0], val_data.shape[0], test_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9638b3a-0e9d-4a6a-abd9-85f4251c49f9",
   "metadata": {},
   "source": [
    "## Train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34b120a7-0dbf-43f5-b953-0ddeb7265d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer =  tf.compat.v1.initializers.glorot_uniform()\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(128, 128)),\n",
    "  tf.keras.layers.Dense(1800, activation='tanh', kernel_initializer=initializer),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adamax',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2c4f05d-579c-43df-adbe-5feadf6d49a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 5, \n",
    "                                        restore_best_weights = True)\n",
    "\n",
    "reduce_lr =  tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=3, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba437cb4-40f4-4cd8-9253-92cc387cc96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1000/1000 [==============================] - 160s 156ms/step - loss: 0.7965 - accuracy: 0.6474 - val_loss: 0.4845 - val_accuracy: 0.8117 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 0.4383 - accuracy: 0.8101 - val_loss: 0.3104 - val_accuracy: 0.9218 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 0.2864 - accuracy: 0.8913 - val_loss: 0.2104 - val_accuracy: 0.9485 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "1000/1000 [==============================] - 159s 159ms/step - loss: 0.2179 - accuracy: 0.9220 - val_loss: 0.1639 - val_accuracy: 0.9615 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "1000/1000 [==============================] - 154s 154ms/step - loss: 0.1510 - accuracy: 0.9520 - val_loss: 0.1600 - val_accuracy: 0.9507 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "1000/1000 [==============================] - 157s 156ms/step - loss: 0.1380 - accuracy: 0.9523 - val_loss: 0.3584 - val_accuracy: 0.8227 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 0.1167 - accuracy: 0.9611 - val_loss: 0.1295 - val_accuracy: 0.9517 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 0.0922 - accuracy: 0.9701 - val_loss: 0.0836 - val_accuracy: 0.9758 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 0.0829 - accuracy: 0.9734 - val_loss: 0.2531 - val_accuracy: 0.9100 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 0.0823 - accuracy: 0.9751 - val_loss: 0.0689 - val_accuracy: 0.9865 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 0.0506 - accuracy: 0.9861 - val_loss: 0.1754 - val_accuracy: 0.9440 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "1000/1000 [==============================] - 155s 155ms/step - loss: 0.0557 - accuracy: 0.9841 - val_loss: 0.0607 - val_accuracy: 0.9827 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "1000/1000 [==============================] - 152s 152ms/step - loss: 0.0425 - accuracy: 0.9884 - val_loss: 0.0545 - val_accuracy: 0.9837 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 0.0552 - accuracy: 0.9857 - val_loss: 0.0585 - val_accuracy: 0.9805 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 0.0507 - accuracy: 0.9846 - val_loss: 0.0579 - val_accuracy: 0.9803 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 0.0407 - accuracy: 0.9893 - val_loss: 0.1546 - val_accuracy: 0.9457 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 0.0333 - accuracy: 0.9899 - val_loss: 0.0463 - val_accuracy: 0.9877 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 0.0402 - accuracy: 0.9877 - val_loss: 0.1212 - val_accuracy: 0.9473 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 0.0329 - accuracy: 0.9894 - val_loss: 0.0406 - val_accuracy: 0.9875 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "1000/1000 [==============================] - 157s 157ms/step - loss: 0.0400 - accuracy: 0.9869 - val_loss: 0.0714 - val_accuracy: 0.9735 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "1000/1000 [==============================] - 153s 154ms/step - loss: 0.0433 - accuracy: 0.9877 - val_loss: 0.0588 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 0.0116 - accuracy: 0.9977 - val_loss: 0.0431 - val_accuracy: 0.9868 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 0.3129 - val_accuracy: 0.9355 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "1000/1000 [==============================] - 153s 153ms/step - loss: 0.0168 - accuracy: 0.9955 - val_loss: 0.0723 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "125/125 [==============================] - 10s 83ms/step - loss: 0.0437 - accuracy: 0.9868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.043656013906002045, 0.9867500066757202]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_label, epochs=30, validation_data=(val_data, val_label), callbacks=[earlystopping, reduce_lr]) #20\n",
    "model.evaluate(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "81226e03-183f-4811-8011-4700daad716c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling the intensity..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 262144/262144 [00:27<00:00, 9537.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing between 0 and 1..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 262144/262144 [00:10<00:00, 24461.32it/s]\n"
     ]
    }
   ],
   "source": [
    "mask_size = 11\n",
    "shift = 0.03\n",
    "signal_masked = preprocess_NN(signal, mask_size, shift)\n",
    "#ignal_masked_px = px.signals.ElectronDiffraction2D(signal_masked.reshape(nx, ny, kx, ky))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "e5fc754b-865a-4893-ad83-bc39394b36a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling the intensity..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 262144/262144 [00:29<00:00, 8979.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing between 0 and 1..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 262144/262144 [00:12<00:00, 21330.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 262144/262144 [00:00<00:00, 368395.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.00932312011719\n"
     ]
    }
   ],
   "source": [
    "shift = 0.024\n",
    "signal_masked = preprocess_NN(signal, mask_size, shift)\n",
    "#signal_masked_px = px.signals.ElectronDiffraction2D(signal_masked.reshape(nx, ny, kx, ky))\n",
    "predictions = model.predict(signal_masked)\n",
    "signal_prediction = np.zeros((nx*ny))\n",
    "for pixel in tqdm(range(nx*ny)):\n",
    "    signal_prediction[pixel] = np.argmax(predictions[pixel])\n",
    "signal_prediction = signal_prediction.reshape(nx, ny)\n",
    "phase_map_ANN = hs.signals.Signal2D(signal_prediction)\n",
    "error = np.count_nonzero(np.abs((phase_map_ANN-ground_truth).data))/(512*512)\n",
    "plt.imshow(phase_map_ANN)\n",
    "print(100 - error*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf509896-6db2-4f66-bc54-f9f435a8a302",
   "metadata": {},
   "source": [
    "### Optionally: Test shifts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a61a695-dc4e-41bf-a930-423702f347bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling the intensity..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 262144/262144 [00:27<00:00, 9525.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing between 0 and 1..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 262144/262144 [00:09<00:00, 26602.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting..\n",
      "   1/8192 [..............................] - ETA: 11:53"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192/8192 [==============================] - 721s 88ms/step\n",
      "creating phase map\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 262144/262144 [00:00<00:00, 310711.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1.016998291015625% when shift = 0.02\n",
      "Scaling the intensity..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 262144/262144 [00:28<00:00, 9203.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing between 0 and 1..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 262144/262144 [00:10<00:00, 24372.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting..\n",
      "   1/8192 [..............................] - ETA: 3:24"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192/8192 [==============================] - 732s 89ms/step\n",
      "creating phase map\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 262144/262144 [00:00<00:00, 273984.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1.00860595703125% when shift = 0.022\n",
      "Scaling the intensity..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 262144/262144 [00:28<00:00, 9092.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing between 0 and 1..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 262144/262144 [00:11<00:00, 23644.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting..\n",
      "   1/8192 [..............................] - ETA: 3:41"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192/8192 [==============================] - 716s 87ms/step\n",
      "creating phase map\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 262144/262144 [00:01<00:00, 233203.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1.0040283203125% when shift = 0.023999999999999997\n",
      "Scaling the intensity..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 262144/262144 [00:28<00:00, 9295.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing between 0 and 1..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 262144/262144 [00:10<00:00, 25061.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting..\n",
      "   1/8192 [..............................] - ETA: 3:33"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192/8192 [==============================] - 747s 91ms/step\n",
      "creating phase map\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 262144/262144 [00:01<00:00, 241185.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 1.001739501953125% when shift = 0.025999999999999995\n",
      "Scaling the intensity..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 262144/262144 [00:27<00:00, 9362.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing between 0 and 1..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 262144/262144 [00:10<00:00, 25283.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting..\n",
      "   1/8192 [..............................] - ETA: 3:33"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192/8192 [==============================] - 725s 89ms/step\n",
      "creating phase map\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 262144/262144 [00:01<00:00, 257045.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.9990692138671875% when shift = 0.027999999999999994\n",
      "Scaling the intensity..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 262144/262144 [00:27<00:00, 9423.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing between 0 and 1..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 262144/262144 [00:10<00:00, 25610.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting..\n",
      "   1/8192 [..............................] - ETA: 3:24"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192/8192 [==============================] - 727s 89ms/step\n",
      "creating phase map\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 262144/262144 [00:00<00:00, 287518.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.998687744140625% when shift = 0.029999999999999992\n",
      "Scaling the intensity..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 262144/262144 [00:27<00:00, 9431.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing between 0 and 1..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 262144/262144 [00:10<00:00, 25892.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting..\n",
      "   1/8192 [..............................] - ETA: 3:26"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192/8192 [==============================] - 717s 88ms/step\n",
      "creating phase map\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 262144/262144 [00:00<00:00, 266188.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.9967803955078125% when shift = 0.03199999999999999\n",
      "Scaling the intensity..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 262144/262144 [00:27<00:00, 9464.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing between 0 and 1..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 262144/262144 [00:10<00:00, 26011.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting..\n",
      "   1/8192 [..............................] - ETA: 3:33"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192/8192 [==============================] - 720s 88ms/step\n",
      "creating phase map\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 262144/262144 [00:00<00:00, 262191.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.998687744140625% when shift = 0.03399999999999999\n",
      "Scaling the intensity..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 262144/262144 [00:27<00:00, 9481.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing between 0 and 1..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 262144/262144 [00:10<00:00, 25831.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting..\n",
      "   1/8192 [..............................] - ETA: 3:16"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192/8192 [==============================] - 704s 86ms/step\n",
      "creating phase map\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 262144/262144 [00:01<00:00, 252095.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.9990692138671875% when shift = 0.03599999999999999\n",
      "Scaling the intensity..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 262144/262144 [00:27<00:00, 9473.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing between 0 and 1..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 262144/262144 [00:10<00:00, 26009.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting..\n",
      "   1/8192 [..............................] - ETA: 3:24"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192/8192 [==============================] - 715s 87ms/step\n",
      "creating phase map\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 262144/262144 [00:01<00:00, 233240.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.9998321533203125% when shift = 0.037999999999999985\n",
      "Lowest error: 0.9967803955078125% when shift = 0.03199999999999999\n"
     ]
    }
   ],
   "source": [
    "#shift_array = np.arange(0.001 , 0.1, 0.02)\n",
    "#shift_array = np.arange(0.010 , 0.09, 0.02)\n",
    "shift_array = np.arange(0.02 , 0.04, 0.002)\n",
    "mask_size = 11\n",
    "errors = np.zeros_like(shift_array)\n",
    "ground_truth = hs.io.load(r'H:\\Ground truths\\New-ground-truth\\ground_truth_all.hdf5')\n",
    "\n",
    "for ind, shift in enumerate(shift_array):\n",
    "    signal_masked = preprocess_NN(signal, mask_size, shift)\n",
    "    #signal_masked_px = px.signals.ElectronDiffraction2D(signal_masked.reshape(nx, ny, kx, ky))\n",
    "    print('predicting..')\n",
    "    predictions = model.predict(signal_masked)\n",
    "    signal_prediction = np.zeros((nx*ny))\n",
    "    print('creating phase map')\n",
    "    for pixel in tqdm(range(nx*ny)):\n",
    "        signal_prediction[pixel] = np.argmax(predictions[pixel])\n",
    "    signal_prediction = signal_prediction.reshape(nx, ny)\n",
    "    phase_map_ANN = hs.signals.Signal2D(signal_prediction)\n",
    "    error = np.count_nonzero(np.abs((phase_map_ANN-ground_truth).data))/(512*512)\n",
    "    errors[ind] = error\n",
    "    print('Error: {}% when shift = {}'.format(error*100, shift))\n",
    "    del signal_masked\n",
    "    gc.collect()\n",
    "\n",
    "limit = 0.00001\n",
    "index = np.ma.MaskedArray(errors, errors < limit)\n",
    "index = np.ma.argmin(index)\n",
    "print('Lowest error: {}% when shift = {}'.format(errors[index]*100, shift_array[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "1c68fa59-e7c4-4de2-8371-087ad8097ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'H:\\PhD\\CNN\\Emil_2xxx_data\\SPED_512x512\\models'.replace('\\\\','\\\\\\\\')\n",
    "model.save(directory + '/model_final_2023')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
